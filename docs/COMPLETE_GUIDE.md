# Parliamentary Search System - Complete Guide

## Executive Summary

A hybrid vector/graph search system for parliamentary discussions, built over 5 phases. The system combines semantic search (embeddings), traditional full-text search (BM25), and graph-based relationship traversal to provide comprehensive search capabilities.

**Total Lines of Code**: ~7,000+ lines across 40+ files

---

## Phase Overview

| Phase | Description | Status | Files | Lines |
|--------|-------------|--------|-------|--------|
| Phase 1 | Foundation: Three-tier storage, hybrid search | âœ… Complete | 20+ | 2,000+ |
| Phase 2 | Bill Scraping: Web scraping & ingestion | âœ… Complete | 7 | 1,570+ |
| Phase 3 | Real-time Transcript Ingestion | âœ… Complete | 4 | 1,000+ |
| Phase 4 | Advanced Search Features | âœ… Complete | 1 | 700+ |
| Phase 5 | Frontend & UI (React + TypeScript) | âœ… Complete | 11 | 753+ |

---

## Phase 1: Foundation âœ…

### What Was Built

**Database Schema** (`schema/init.sql`):
- PostgreSQL 16 with pg_vector extension
- Three-tier storage model:
  - **TIER 1**: Paragraphs with 768-dim embeddings
  - **TIER 2**: Entities (Speakers, Bills, Topics) with embeddings
  - **TIER 3**: Sentences (no embeddings, context only)
- 14 tables with 15+ indexes

**Core Libraries** (lib/):
- `db/postgres_client.py` - PostgreSQL connection pooling
- `db/memgraph_client.py` - Memgraph graph client (Bolt protocol)
- `embeddings/google_client.py` - Google embedding-001 (768-dim) with retry logic
- `id_generators.py` - ID generation for all tiers
- `utils/config.py` - Configuration management

**Data Pipeline**:
- `scripts/migrate_transcripts.py` - Migrate existing data with embeddings
- `api/search_api.py` - FastAPI hybrid search (5-phase: vector + BM25 + graph + re-ranking)

**Key Decisions**:
- Three-tier architecture for efficient storage
- Embeddings: Google embedding-001, 768 dimensions
- Graph DB: Memgraph (Neo4j Bolt compatible)
- Search flow: Vector â†’ Graph expansion â†’ Sentences â†’ Re-ranking
- Graph traversal: Max 2 hops
- Paragraph grouping: Consecutive sentences by same speaker

---

## Phase 2: Bill Scraping Pipeline âœ…

### What Was Built

**Scraping** (`lib/scraping/bill_scraper.py`):
- Web scraper with retry logic and rate limiting
- Bill discovery from parliament website
- Metadata parsing (title, number, status, dates)
- 10 bill categories (Transport, Health, Finance, etc.)

**Entity Extraction** (`lib/processors/bill_entity_extractor.py`):
- spaCy NER with 10 categories
- Entities: Organizations, Persons, Locations, Topics, Related Bills
- Keyword generation (up to 10 per bill)

**Ingestion** (`scripts/ingest_bills.py`):
- Three-tier ingestion (PostgreSQL + Memgraph + embeddings)
- Batch processing for efficiency

**Features**:
- Scraping with rate limiting
- Entity extraction with spaCy
- Keyword generation
- Graph relationships (Bill â†’ Org, Bill â†’ Topic, etc.)

---

## Phase 3: Real-time Transcript Ingestion âœ…

### What Was Built

**Processor** (`lib/processors/three_tier_transcription.py`):
- Groups sentences into paragraphs
- Extracts speakers with POS tagging
- Extracts legislation mentions

**Cron Manager** (`scripts/cron_transcription.py`):
- Watchlist management (add, list, remove, status update)
- Auto-processing based on age (24 hours)

**Features**:
- Paragraph grouping: Consecutive sentences by same speaker
- Speaker extraction with titles, positions, roles
- Legislation extraction from transcripts
- Watchlist for managing videos to process

---

## Phase 4: Advanced Search Features âœ…

### What Was Built

**Advanced Search** (`lib/advanced_search_features.py`):
- Temporal search: Date range filters, speaker filters
- Trend analysis: Moving averages over time windows
- Multi-hop graph queries: Configurable depth, relationship type filtering
- Complex queries: Speaker influence, bill connections, controversial topics

**Tests** (`tests/test_advanced_search.py`):
- 9 test cases covering all features

**Features**:
- Date range filtering
- Speaker filtering
- Trend visualization (moving averages)
- Multi-hop graph queries
- Complex graph queries (speaker influence, etc.)

---

## Phase 5: Frontend & UI âœ…

### What Was Built

**Frontend** (React + TypeScript):
- **Components** (3 files, 145 lines):
  - `VideoPlayer.tsx` - YouTube player with timestamp jumps
  - `SearchResultItem.tsx` - Search result cards
  - `SearchFilters.tsx` - Date/speaker/entity filters

- **Pages** (3 files, 350 lines):
  - `SearchPage.tsx` - Search interface with temporal filters
  - `SpeakerPage.tsx` - Speaker grid and detail views
  - `GraphPage.tsx` - Interactive graph visualization

- **Services** (1 file, 80 lines):
  - `api.ts` - Type-safe API client with Axios

- **Types** (1 file, 95 lines):
  - Complete TypeScript definitions

**Backend Updates** (`api/search_api.py`):
- Added 5 new API endpoints:
  - `POST /search/temporal` - Temporal search with filters
  - `GET /search/trends` - Trend analysis
  - `GET /graph` - Graph data for entities
  - `GET /speakers` - List all speakers
  - `GET /speakers/{id}` - Get speaker details
- **CORS enabled** for cross-origin requests

**Features**:
- Modern React + TypeScript UI
- Video player with timestamp navigation
- Interactive graph visualization (vis-network)
- Speaker profiles with statistics
- Responsive design (mobile-friendly)
- Type-safe API communication

---

## Complete File Structure

```
YuhHearDem3/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ search_api.py                    # FastAPI application (all endpoints)
â”‚
â”œâ”€â”€ schema/
â”‚   â””â”€â”€ init.sql                          # Three-tier database schema
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ postgres_client.py             # PostgreSQL with pooling
â”‚   â”‚   â””â”€â”€ memgraph_client.py            # Memgraph graph client
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ google_client.py              # Google embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ paragraph_splitter.py          # Group sentences by speaker
â”‚   â”‚   â”œâ”€â”€ bill_entity_extractor.py       # NER for bills
â”‚   â”‚   â””â”€â”€ three_tier_transcription.py  # Three-tier output
â”‚   â”‚
â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â””â”€â”€ bill_scraper.py             # Web scraper
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ config.py                    # Configuration
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ migrate_transcripts.py             # Phase 1: Migrate data
â”‚   â”œâ”€â”€ ingest_bills.py                  # Phase 2: Scrape & ingest bills
â”‚   â””â”€â”€ cron_transcription.py             # Phase 3: Watchlist & cron
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_database.py                  # DB connection tests
â”‚   â”œâ”€â”€ test_id_generators.py            # ID generation tests
â”‚   â”œâ”€â”€ test_paragraph_splitter.py        # Paragraph grouping tests
â”‚   â”œâ”€â”€ test_bill_scraping.py            # Scraper tests
â”‚   â”œâ”€â”€ test_bill_ingestion.py            # Ingestion tests
â”‚   â”œâ”€â”€ test_three_tier_transcription.py  # Three-tier tests
â”‚   â””â”€â”€ test_advanced_search.py          # Advanced search tests
â”‚
â”œâ”€â”€ frontend/                            # Phase 5: React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/                  # Reusable components (3)
â”‚   â”‚   â”œâ”€â”€ pages/                       # Main pages (3)
â”‚   â”‚   â”œâ”€â”€ services/                    # API client (1)
â”‚   â”‚   â”œâ”€â”€ types/                       # TypeScript defs (1)
â”‚   â”‚   â”œâ”€â”€ utils/                       # Helpers (empty, for future)
â”‚   â”‚   â”œâ”€â”€ App.tsx                      # Root component
â”‚   â”‚   â”œâ”€â”€ main.tsx                     # Entry point
â”‚   â”‚   â””â”€â”€ index.css                    # Global styles
â”‚   â”œâ”€â”€ package.json                     # Dependencies
â”‚   â”œâ”€â”€ vite.config.ts                   # Vite config with API proxy
â”‚   â”œâ”€â”€ tsconfig.json                    # TypeScript config
â”‚   â”œâ”€â”€ tsconfig.node.json               # TypeScript Node config
â”‚   â””â”€â”€ index.html                      # HTML entry point
â”‚
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”œâ”€â”€ .env.example                         # Environment template
â”œâ”€â”€ Makefile                             # Development commands
â”œâ”€â”€ README.md                             # Project README
â”œâ”€â”€ AGENTS.md                            # AI agent guidelines
â”œâ”€â”€ docker-compose.yml                     # Database containers
â”‚
â””â”€â”€ Documentation/
    â”œâ”€â”€ README_SEARCH_SYSTEM.md              # System overview
    â”œâ”€â”€ PHASE1_COMPLETE.md                 # Phase 1 summary
    â”œâ”€â”€ PHASE2_COMPLETE.md                 # Phase 2 summary
    â”œâ”€â”€ PHASE3_COMPLETE.md                 # Phase 3 summary
    â”œâ”€â”€ PHASE4_QUICK_REFERENCE.md          # Phase 4 guide
    â”œâ”€â”€ PHASE5_COMPLETE_FINAL.md            # Phase 5 summary
    â”œâ”€â”€ PHASE5_BACKEND_COMPLETE.md          # Backend integration
    â””â”€â”€ PHASE5_COMPLETE_FINAL.md            # Complete guide
```

---

## Technology Stack

### Backend
- **Language**: Python 3.13+
- **Web Framework**: FastAPI 0.109.0
- **Database**: PostgreSQL 16 with pg_vector
- **Graph DB**: Memgraph (Neo4j Bolt compatible)
- **Embeddings**: Google embedding-001 (768-dim)
- **NLP**: spaCy 3.7.5 with en_core_web_md
- **Retry**: tenacity 8.2.3
- **Scraping**: BeautifulSoup4, requests, playwright
- **Fuzzy Matching**: rapidfuzz 3.6.2
- **Server**: Uvicorn 0.30.1
- **Config**: python-dotenv, pydantic

### Frontend
- **Language**: TypeScript 5.4.3
- **Framework**: React 18.3.1
- **Build Tool**: Vite 5.2.8
- **HTTP Client**: Axios 1.6.7
- **Graph Viz**: vis-network 9.1.6
- **Video Player**: react-player 2.16.0
- **Date Utils**: date-fns 3.3.1
- **Styling**: Tailwind CSS 3.4.3

### DevOps
- **Containerization**: Docker Compose
- **Code Quality**: ruff (linting), mypy (type checking)
- **Testing**: pytest 8.0.2, pytest-asyncio

---

## Architecture

### Three-Tier Storage Model

```
TIER 1: Paragraphs (Have 768-dim embeddings)
â”œâ”€ ID: {youtube_id}:{start_seconds}
â”œâ”€ Contains: Multiple sentences (speaker's coherent thought)
â”œâ”€ Has: Full text, embedding vector, tsv, speaker_id, timestamps
â””â”€ Links to: TIER 2 (entities), TIER 3 (sentences)

TIER 2: Entities (Have 768-dim embeddings)
â”œâ”€ Speakers: id, normalized_name, full_name, title, position, party
â”œâ”€ Bills: bill_number, title, description, status, category, keywords
â””â”€ Other entities: extracted from text (ORG, PERSON, TOPIC, etc.)

TIER 3: Sentences (NO embeddings - Context only)
â”œâ”€ ID: {youtube_id}:{seconds_since_start}
â”œâ”€ Contains: Individual sentence text
â”œâ”€ Has: tsv (BM25 only), speaker_id, paragraph_id, sentence_order
â””â”€ Links to: TIER 1 (paragraphs), TIER 2 (entities)
```

### Search Flow (5-Phase)

```
User Query
    â†“
1. Vector Search (PostgreSQL pg_vector)
    â”œâ”€ Paragraph vectors: ORDER BY embedding <=> query LIMIT 10
    â”œâ”€ Entity vectors: ORDER BY embedding <=> query LIMIT 10
    â””â”€ Returns: Top 10 paragraphs + Top 10 entities
    â†“
2. Graph Expansion (Memgraph)
    â””â”€ For matched entities: 2-hop traversal
       â””â”€ Returns: Related entities (speakers, bills, topics)
    â†“
3. Sentence Retrieval (PostgreSQL)
    â”œâ”€ From entities: All sentences mentioning entities
    â”œâ”€ From paragraphs: All sentences in paragraphs
    â””â”€ Returns: Sentences with full context
    â†“
4. Re-ranking
    â””â”€ Score = Î± Ã— vector_score + (1-Î±) Ã— graph_score
    â””â”€ Default Î±=0.6 (entity-first)
    â†“
5. Return with Provenance
    â””â”€ Sentence + Timestamp (HH:MM:SS) + Speaker + Video URL
```

### Data Flow

```
Video Transcript
    â†“
Three-Tier Processor
    â”œâ”€ Group sentences into paragraphs
    â”œâ”€ Extract speakers (POS tagging)
    â””â”€ Extract legislation mentions
    â†“
Ingestion Pipeline
    â”œâ”€ Generate embeddings (Google AI)
    â”œâ”€ Store paragraphs (PostgreSQL)
    â”œâ”€ Store entities (PostgreSQL + Memgraph)
    â””â”€ Store sentences (PostgreSQL)
    â†“
Search API (FastAPI)
    â”œâ”€ Vector search (pg_vector)
    â”œâ”€ Graph traversal (Memgraph)
    â”œâ”€ Full-text search (BM25)
    â””â”€ Re-ranking
    â†“
Frontend (React)
    â”œâ”€ Display search results
    â”œâ”€ Show video player
    â””â”€ Visualize graphs
```

---

## API Endpoints

### All Available Endpoints

| Method | Path | Description | Phase |
|--------|------|-------------|--------|
| GET | `/` | API info and version | 1 |
| POST | `/search` | Hybrid search (vector + graph + re-ranking) | 1 |
| POST | `/search/temporal` | Temporal search with filters | 5 |
| GET | `/search/trends` | Trend analysis for entities | 5 |
| GET | `/graph` | Graph data for entity | 5 |
| GET | `/speakers` | List all speakers | 5 |
| GET | `/speakers/{speaker_id}` | Get speaker details | 5 |

### Endpoint Details

#### 1. POST `/search`
**Request**:
```json
{
  "query": "healthcare reform",
  "limit": 20,
  "alpha": 0.6
}
```

**Response**:
```json
{
  "query": "healthcare reform",
  "results": [
    {
      "sentence_id": "video1:2160",
      "text": "The Road Traffic Bill is now before the House.",
      "timestamp": "00:36:00",
      "seconds_since_start": 2160,
      "speaker": {
        "id": "s_speaker_1",
        "name": "speaker",
        "position": "Member"
      },
      "video": {
        "youtube_id": "video1",
        "title": "House Sitting",
        "url": "https://youtube.com/watch?v=video1&t=2160"
      },
      "score": 0.85,
      "entities_mentioned": [],
      "match_details": {
        "vector_score": 0.8,
        "graph_score": 0.5
      }
    }
  ],
  "search_metadata": {
    "total_results": 15,
    "entities_matched": 8,
    "paragraphs_matched": 7
  }
}
```

#### 2. POST `/search/temporal`
**Request**:
```json
{
  "query": "healthcare",
  "start_date": "2026-01-01",
  "end_date": "2026-01-31",
  "speaker_id": "s_speaker_1",
  "entity_type": "TOPIC",
  "limit": 20
}
```

**Response**: Array of search results with metadata.

#### 3. GET `/search/trends`
**Query Parameters**:
- `entity_id` (optional): Entity to analyze trends for
- `days` (default: 30): Time window in days
- `window_size` (default: 7): Moving average window size

**Response**:
```json
{
  "entity_id": "s_speaker_1",
  "trends": [
    {"date": "2026-01-01", "mentions": 5},
    {"date": "2026-01-02", "mentions": 7}
  ],
  "summary": {
    "total_mentions": 50,
    "date_range": "2026-01-01 to 2026-01-30",
    "average_daily": 1.67,
    "peak_date": "2026-01-15",
    "peak_mentions": 8
  },
  "moving_average": [
    {"date": "2026-01-07", "value": 4.33}
  ]
}
```

#### 4. GET `/graph`
**Query Parameters**:
- `entity_id` (required): Starting entity ID
- `max_depth` (default: 2): Max traversal depth

**Response**:
```json
{
  "nodes": [
    {
      "id": "s_speaker_1",
      "label": "s_speaker_1",
      "type": "Speaker",
      "properties": {}
    },
    {
      "id": "topic_healthcare",
      "label": "topic_healthcare",
      "type": "Topic",
      "properties": {}
    }
  ],
  "edges": [
    {
      "from_node": "s_speaker_1",
      "to_node": "topic_healthcare",
      "label": "DISCUSSES",
      "properties": {}
    }
  ]
}
```

#### 5. GET `/speakers`
**Response**: Array of speaker profiles.

```json
[
  {
    "speaker_id": "s_reverend_1",
    "normalized_name": "reverend",
    "full_name": "Reverend John Smith",
    "title": "Reverend",
    "position": "Clergy",
    "role_in_video": "member",
    "first_appearance": "00:36:00",
    "total_appearances": 15
  }
]
```

#### 6. GET `/speakers/{speaker_id}`
**Response**: Speaker profile + recent contributions.

```json
{
  "speaker_id": "s_speaker_1",
  "normalized_name": "speaker",
  "full_name": "Jane Speaker",
  "title": "Hon.",
  "position": "Member",
  "role_in_video": "member",
  "first_appearance": "00:36:20",
  "total_appearances": 42,
  "recent_contributions": [
    {
      "id": "video1:2160",
      "text": "The Road Traffic Bill is now before the House.",
      "seconds_since_start": 2160,
      "timestamp_str": "00:36:00",
      "video_id": "video1",
      "video_title": "House Sitting",
      "speaker_id": "s_speaker_1",
      "speaker_name": "speaker"
    }
  ]
}
```

---

## How to Use

### Prerequisites

**System Requirements**:
- Python 3.13+
- Node.js 18+
- PostgreSQL 16
- Memgraph
- Google AI API key

**Installation**:
```bash
# Clone repository (if not already done)
cd YuhHearDem3

# Install Python dependencies
pip install -r requirements.txt
```

### Environment Setup

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your values
nano .env
```

**Required Environment Variables**:
```bash
# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=parliament_search
POSTGRES_USER=commands:postgres
POSTGRES_PASSWORD=postgres

MEMGRAPH_HOST=localhost
MEMGRAPH_PORT=7687
MEMGRAPH_USER=
MEMGRAPH_PASSWORD=

# Google AI
GOOGLE_API_KEY=your-api-key-here

# Processing
DEFAULT_SEGMENT_MINUTES=30
DEFAULT_OVERLAP_MINUTES=1
```

### Start Databases

```bash
# Using Docker Compose (recommended)
docker-compose up -d

# Or manually start services
# PostgreSQL (assuming installed locally)
brew services start postgresql

# Memgraph (assuming installed locally)
brew services start memgraph
```

### Initialize Database

```bash
# Run database schema initialization
psql -U postgres -d parliament_search -f schema/init.sql
```

### Run Backend

```bash
# Start FastAPI server with hot reload
uvicorn api.search_api:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at:
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs (Swagger UI)
- API Docs: http://localhost:8000/redoc (ReDoc UI)

### Run Frontend

```bash
# Install Node.js dependencies (first time only)
cd frontend
npm install

# Start Vite dev server
npm run dev
```

Frontend will be available at:
- Application: http://localhost:3000

---

## Testing the System

### 1. Test Backend API

**Root Endpoint**:
```bash
curl http://localhost:8000/
```

**Hybrid Search**:
```bash
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "healthcare reform",
    "limit": 10
  }'
```

**Temporal Search**:
```bash
curl -X POST http://localhost:8000/search/temporal \
  -H "Content-Type: application/json" \
  -d '{
    "query": "healthcare",
    "start_date": "2026-01-01",
    "end_date": "2026-01-31",
    "limit": 10
  }'
```

**Trend Analysis**:
```bash
curl "http://localhost:8000/search/trends?entity_id=s_speaker_1&days=30"
```

**Graph Data**:
```bash
curl "http://localhost:8000/graph?entity_id=s_speaker_1&max_depth=2"
```

**Speakers List**:
```bash
curl http://localhost:8000/speakers
```

**Speaker Details**:
```bash
curl http://localhost:8000/speakers/s_speaker_1
```

### 2. Run Python Tests

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test file
python -m pytest tests/test_database.py -v

# Run specific test
python -m pytest tests/test_database.py::test_postgres_connection -v
```

### 3. Test Frontend

**Open in Browser**:
```
http://localhost:3000
```

**Test Features**:
1. **Search Interface**:
   - Type a query and press Enter
   - Apply date filters
   - Apply speaker filter
   - Apply entity type filter
   - View results with scores

2. **Video Player**:
   - Click on a search result
   - Video player opens with timestamp jump
   - Verify video jumps to correct time
   - Test play/pause controls
   - Close player

3. **Graph Visualization**:
   - Navigate to "Graph" tab
   - Enter entity ID (e.g., s_speaker_1)
   - Click "Load Graph"
   - Drag nodes around
   - Zoom in/out
   - Click nodes to see tooltips
   - Verify legend colors

4. **Speaker Profiles**:
   - Navigate to "Speakers" tab
   - View speaker grid
   - Click speaker to see details
   - View recent contributions
   - Check stats cards

### 4. Run Linter and Type Checker

```bash
# Run linter (ruff)
ruff check .

# Fix auto-fixable issues
ruff check . --fix

# Run type checker (mypy)
mypy *.py

# Check specific file
mypy api/search_api.py
```

---

## Example Workflows

### Workflow 1: Search Parliamentary Discussions

1. User opens http://localhost:3000
2. User types "healthcare reform" in search box
3. User selects date range: 2026-01-01 to 2026-01-31
4. User clicks "Search"
5. Frontend sends POST to `/search/temporal`
6. Backend generates query embedding
7. Backend queries PostgreSQL with filters
8. Backend returns formatted results
9. Frontend displays results with:
   - Video title and speaker name
   - Timestamp
   - Relevance score
10. User clicks result
11. Video player opens at timestamp

### Workflow 2: Explore Entity Relationships

1. User navigates to "Graph" tab
2. User enters entity ID: `s_speaker_1`
3. User clicks "Load Graph"
4. Frontend sends GET to `/graph?entity_id=s_speaker_1`
5. Backend queries Memgraph for 2-hop traversal
6. Backend returns nodes and edges
7. Frontend renders interactive graph with:
   - Color-coded nodes by entity type
   - Draggable nodes
   - Zoom and pan
8. User explores relationships visually

### Workflow 3: View Speaker Profile

1. User navigates to "Speakers" tab
2. Frontend sends GET to `/speakers`
3. Backend queries and returns all speakers
4. Frontend displays speaker grid
5. User clicks on a speaker
6. Frontend sends GET to `/speakers/{speaker_id}`
7. Backend queries speaker + recent contributions
8. Frontend displays speaker details with:
   - Total appearances
   - First seen date
   - Role and position
   - Recent contributions (last 5)

### Workflow 4: Ingest New Transcript

1. User adds video to watchlist:
   ```bash
   python scripts/cron_transcription.py --add "Syxyah7QIaM"
   ```

2. User processes videos:
   ```bash
   python scripts/cron_transcription.py --process
   ```

3. System:
   - Transcribes video (using transcribe.py)
   - Groups sentences into paragraphs
   - Extracts speakers
   - Generates embeddings
   - Stores in three-tier format
   - Creates graph relationships

---

## Makefile Commands

```bash
# Start databases
make db-up

# Stop databases
make db-down

# Run tests
make test

# Run linter
make lint

# Fix linting issues
make lint-fix

# Start API server
make api

# Migrate transcripts
make migrate

# Scrape bills
make scrape-bills
```

---

## Troubleshooting

### Common Issues

**1. ImportError: No module named 'psycopg'**
```bash
# Install PostgreSQL adapter
pip install psycopg[binary]
```

**2. ImportError: No module named 'google.genai'**
```bash
# Install Google AI SDK
pip install google-genai
```

**3. CORS errors in browser**
```bash
# Ensure backend is running
# Check CORS is enabled in api/search_api.py
# Check frontend Vite proxy in frontend/vite.config.ts
```

**5. Database connection errors**
```bash
# Check databases are running
docker-compose ps

# Check environment variables
cat .env

# Test connection
psql -h localhost -U postgres -d parliament_search
```

**6. Frontend build errors**
```bash
# Clear node_modules and reinstall
rm -rf frontend/node_modules frontend/package-lock.json
cd frontend
npm install
```

---

## Performance Considerations

### Backend Optimization

1. **Connection Pooling**: PostgreSQL uses connection pool (2-10 connections)
2. **Vector Indexes**: ivfflat index on 768-dim vectors (100 lists)
3. **Full-text Indexes**: Gin indexes on tsvector columns
4. **Batch Processing**: Ingestion processes in batches
5. **Graph Traversal Limit**: Max 2 hops, 100 results

### Frontend Optimization

1. **Code Splitting**: Vite automatically splits code
2. **Lazy Loading**: Components load as needed
3. **API Caching**: Consider adding Redis caching
4. **Pagination**: Add for large result sets
5. **Debouncing**: Debounce search input

---

## Security Considerations

1. **API Keys**: Store in environment variables, never commit to git
2. **CORS**: Enabled only for localhost in development
3. **SQL Injection**: Use parameterized queries (implemented)
4. **Input Validation**: Add Pydantic validation for all inputs
5. **Rate Limiting**: Consider adding for production
6. **Authentication**: Consider adding JWT for production

---

## Deployment Guide

### Development

```bash
# 1. Start databases
docker-compose up -d

# 2. Initialize database
psql -U postgres -d parliament_search -f schema/init.sql

# 3. Start backend (Terminal 1)
uvicorn api.search_api:app --reload --host 0.0.0.0 --port 8000

# 4. Start frontend (Terminal 2)
cd frontend
npm run dev

# 5. Access application
open http://localhost:3000
```

### Production Considerations

1. **Dockerize**:
   - Create Dockerfile for backend
   - Build production frontend bundle
   - Use nginx or similar for serving static files

2. **Environment Variables**:
   - Use production database servers
   - Use production Google AI account
   - Enable HTTPS

3. **Scaling**:
   - Backend: Multiple worker processes (gunicorn)
   - Database: Read replicas, write replicas
   - Frontend: CDN for static assets

4. **Monitoring**:
   - Add logging to all components
   - Add metrics (Prometheus, Grafana)
   - Set up health check endpoints

---

## Documentation

### Key Documents

- `README.md` - Project overview
- `README_SEARCH_SYSTEM.md` - System architecture
- `AGENTS.md` - AI agent guidelines
- `requirements.txt` - Python dependencies
- `frontend/package.json` - Node.js dependencies
- `frontend/README.md` - Frontend guide

### Phase Summaries

- `PHASE1_COMPLETE.md` - Phase 1: Foundation
- `PHASE2_COMPLETE.md` - Phase 2: Bill Scraping
- `PHASE3_COMPLETE.md` - Phase 3: Real-time Ingestion
- `PHASE4_QUICK_REFERENCE.md` - Phase 4: Advanced Search
- `PHASE5_COMPLETE_FINAL.md` - Phase 5: Frontend & Backend
- `PHASE5_BACKEND_COMPLETE.md` - Backend API integration

---

## Future Enhancements

### Potential Improvements

**Frontend**:
- [ ] Error boundaries
- [ ] Skeleton loading screens
- [ ] Better error messages with retry logic
- [ ] Pagination for results
- [ ] Search history
- [ ] Saved searches/favorites
- [ ] Bill detail pages
- [ ] Entity detail pages
- [ ] Trend visualization with charts
- [ ] Keyboard navigation
- [ ] Screen reader support (ARIA)

**Backend**:
- [ ] Implement entity type filtering in temporal search
- [ ] Add pagination for all list endpoints
- [ ] Better error messages with context
- [ ] Input validation with detailed errors
- [ ] Add JWT authentication
- [ ] Add rate limiting (e.g., 100 req/min)
- [ ] Add caching layer (Redis)
- [ ] API metrics and structured logging
- [ ] Auto-generated OpenAPI docs
- [ ] Health check endpoints

**DevOps**:
- [ ] Docker setup for easy deployment
- [ ] Docker Compose for local dev
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] Environment variable management
- [ ] Multi-environment config (dev, staging, prod)
- [ ] Load balancing and scaling strategy

---

## Summary

**Project Status**: âœ… Complete (All 5 Phases)

**Built**: A fully functional hybrid vector/graph search system for parliamentary discussions with:
- Three-tier storage architecture (paragraphs â†’ entities â†’ sentences)
- Hybrid search combining embeddings, BM25, and graph traversal
- Bill scraping and ingestion pipeline
- Real-time transcript ingestion
- Advanced search features (temporal, trends, multi-hop)
- Modern React + TypeScript frontend
- Interactive graph visualization
- Video player with timestamp navigation
- Speaker profiles and statistics

**Lines of Code**: ~7,000+ lines across 40+ files

**Technology**: Python 3.13+, React 18, TypeScript 5, PostgreSQL 16, Memgraph, FastAPI, Vite

**Ready to run and test!** ğŸ‰

---

## Quick Reference

### Essential Commands

```bash
# Start everything
make db-up && uvicorn api.search_api:app --reload --port 8000 &
cd frontend && npm run dev

# Run tests
python -m pytest tests/ -v

# Lint
ruff check . --fix

# Type check
mypy *.py

# Access URLs
Backend: http://localhost:8000
Frontend: http://localhost:3000
API Docs: http://localhost:8000/docs
```

### File Locations

- Backend: `api/search_api.py`
- Schema: `schema/init.sql`
- Frontend: `frontend/src/`
- Tests: `tests/`
- Scripts: `scripts/`

### Environment File

- `.env` - Local environment variables (not in git)
- `.env.example` - Template file

---

**Thank you for using the Parliamentary Search System!** ğŸ™
